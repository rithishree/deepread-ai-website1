# -*- coding: utf-8 -*-
"""Copy of Handwritten Notes Processor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11gY6SPaDJI0ibUjPXprZUpv9533_Y05T
"""

!sudo apt install tesseract-ocr
!pip install pytesseract
!pip install language-tool-python
!pip install -q -U google-generativeai
!pip install Pillow

!sudo apt install tesseract-ocr

!pip install opencv-python-headless

!pip install google-generativeai

# Handwritten Notes to Enriched Content Processor
# This script is designed for Google Colab.

# --- Step 1: Installation ---
# Before running this script in a Colab notebook, you need to install the necessary packages.
# Copy and run the following commands in a Colab cell:
#
# !sudo apt install tesseract-ocr
# !pip install pytesseract
# !pip install language-tool-python
# !pip install -q -U google-generativeai
# !pip install Pillow

import os
import pytesseract
import language_tool_python
import google.generativeai as genai
from PIL import Image
import warnings

# Suppress warnings that might clutter the output
warnings.filterwarnings("ignore")

# --- Step 2: API Key Configuration ---
# IMPORTANT: To use the AI enrichment feature, you need a Gemini API key.
# 1. Visit https://aistudio.google.com/app/apikey to create your API key.
# 2. In Colab, click the "Key" icon on the left sidebar to open "Secrets".
# 3. Create a new secret named "GEMINI_API_KEY" and paste your key there.
# The code below will securely access this key.

try:
    from google.colab import userdata
    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
    genai.configure(api_key=GEMINI_API_KEY)
except ImportError:
    print("Not in a Colab environment or google.colab not available.")
    # Fallback for local execution (less secure)
    # GEMINI_API_KEY = "YOUR_API_KEY_HERE"
    # genai.configure(api_key=GEMINI_API_KEY)
    print("Please set up your API key manually if running locally.")


# --- Machine Learning Component 1: Optical Character Recognition (OCR) ---
# We use Tesseract, a powerful open-source OCR engine developed by Google.
# It employs pre-trained machine learning models (LSTMs) to recognize
# characters, words, and sentences in images.

def extract_text_from_image(image_path):
    """
    Extracts text from an image file using Tesseract OCR.
    Args:
        image_path (str): The file path to the image of handwritten notes.
    Returns:
        str: The extracted text from the image.
    """
    try:
        print(f"Opening image: {image_path}...")
        with Image.open(image_path) as img:
            print("Extracting text using Tesseract OCR...")
            extracted_text = pytesseract.image_to_string(img)
            print("Text extraction complete.")
            return extracted_text
    except FileNotFoundError:
        return "Error: Image file not found. Please check the file path."
    except Exception as e:
        return f"An error occurred during text extraction: {e}"


# --- NLP Component: Grammar and Spelling Correction ---
# We use 'language-tool-python', a library that acts as a wrapper for LanguageTool.
# LanguageTool is a rule-based system that finds and corrects grammar, style,
# and spelling errors. While not strictly ML, it's a core NLP task.

def correct_grammar_and_spelling(text):
    """
    Corrects grammatical and spelling mistakes in the given text.
    Args:
        text (str): The text to be corrected.
    Returns:
        str: The corrected text.
    """
    print("Initializing grammar correction tool (this may take a moment on first run)...")
    try:
        # Initialize the language tool. It will download necessary files on first use.
        tool = language_tool_python.LanguageTool('en-US')
        print("Applying grammar and spelling corrections...")
        corrected_text = tool.correct(text)
        print("Correction complete.")
        return corrected_text
    except Exception as e:
        print(f"Could not initialize or use the language tool. Error: {e}")
        return text # Return original text if correction fails


# --- Machine Learning Component 2: AI Content Enrichment ---
# This function uses Google's Gemini, a large language model (LLM).
# LLMs are advanced machine learning models trained on vast amounts of text data.
# We prompt the model to act as an expert and enrich the user's notes.

def enrich_content_with_ai(text):
    """
    Uses the Gemini API to enrich the corrected text with additional information.
    Args:
        text (str): The corrected notes to be enriched.
    Returns:
        str: A detailed, enriched version of the notes.
    """
    if not GEMINI_API_KEY:
        return "Error: Gemini API key is not configured. Cannot enrich content."

    print("Connecting to the Gemini API for content enrichment...")
    # Set up the generative model
    model = genai.GenerativeModel('gemini-pro')

    # The prompt is crucial. It tells the AI exactly what to do.
    prompt = f"""
    You are an expert educator and study assistant. Your task is to take the following student's notes, which have been transcribed from handwriting, and enrich them.

    Follow these steps:
    1.  First, present the student's original notes in a cleaned-up and corrected format.
    2.  Next, provide a "Key Concepts" section that summarizes the main points in a bulleted list.
    3.  Then, create an "In-Depth Explanation" section that elaborates on each key concept, providing clear definitions and context.
    4.  Finally, add a "Further Reading & Related Topics" section with suggestions for deeper learning, like related historical events, scientific principles, or key figures.

    Please format the entire output using Markdown for clarity.

    Here are the student's notes:
    ---
    {text}
    ---
    """

    try:
        response = model.generate_content(prompt)
        print("AI enrichment complete.")
        return response.text
    except Exception as e:
        return f"An error occurred with the Gemini API: {e}"


# --- Main Workflow Function ---
def process_handwritten_notes(image_path):
    """
    Orchestrates the entire process from image to enriched content.
    Args:
        image_path (str): The file path to the image of handwritten notes.
    """
    # Step 1: Extract text from the image
    raw_text = extract_text_from_image(image_path)
    if "Error:" in raw_text:
        print(raw_text)
        return

    print("\n--- Extracted Text ---\n")
    print(raw_text)

    # Step 2: Correct grammar and spelling
    corrected_text = correct_grammar_and_spelling(raw_text)
    print("\n--- Corrected Text ---\n")
    print(corrected_text)

    # Step 3: Enrich the content using AI
    enriched_notes = enrich_content_with_ai(corrected_text)
    print("\n--- AI Enriched Notes ---\n")
    print(enriched_notes)


# --- Example Usage ---
# To run this in Google Colab:
# 1.  Upload an image of your handwritten notes to your Colab session.
#     You can do this by clicking the "Files" icon on the left sidebar and then "Upload".
# 2.  Replace 'your_notes.jpg' with the actual filename of your uploaded image.
# 3.  Run the script.

if __name__ == '__main__':
    # Make sure to upload your image file to the Colab environment first!
    # For example, if you upload a file named 'history_notes.png'
    image_file = 'your_notes.jpg'  # <-- IMPORTANT: CHANGE THIS to your image file name

    if not os.path.exists(image_file):
        print(f"File '{image_file}' not found.")
        print("Please upload your notes image and update the 'image_file' variable.")
    else:
        process_handwritten_notes(image_file)

# Handwritten Notes to Enriched Content Processor
# This script is designed for Google Colab.

# --- Step 1: Installation ---
# Before running this script in a Colab notebook, you need to install the necessary packages.
# Copy and run the following commands in a Colab cell:
#
# !sudo apt install tesseract-ocr
# !pip install pytesseract
# !pip install language-tool-python
# !pip install -q -U google-generativeai
# !pip install Pillow

import os
import pytesseract
import language_tool_python
import google.generativeai as genai
from PIL import Image
import warnings

# Suppress warnings that might clutter the output
warnings.filterwarnings("ignore")

# --- Step 2: API Key Configuration ---
# IMPORTANT: To use the AI enrichment feature, you need a Gemini API key.
# 1. Visit https://aistudio.google.com/app/apikey to create your API key.
# 2. In Colab, click the "Key" icon on the left sidebar to open "Secrets".
# 3. Create a new secret named "GEMINI_API_KEY" and paste your key there.
# The code below will securely access this key.

GEMINI_API_KEY = None  # Initialize the key as None
try:
    from google.colab import userdata
    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
    else:
        # This case handles if the secret exists but is empty.
        print("Warning: Secret 'GEMINI_API_KEY' found but it is empty.")

except ImportError:
    print("Not in a Colab environment or google.colab not available.")
    # Fallback for local execution (less secure)
    # GEMINI_API_KEY = "YOUR_API_KEY_HERE"
    # genai.configure(api_key=GEMINI_API_KEY)
    print("Please set up your API key manually if running locally.")
except Exception as e:
    # This will catch the SecretNotFoundError and other potential errors.
    print(f"An error occurred while accessing the GEMINI_API_KEY: {e}")
    print("\n--- ACTION REQUIRED ---")
    print("Please create a secret in your Colab environment:")
    print("1. Click the 'Key' (ðŸ”‘) icon on the left sidebar.")
    print("2. Create a new secret with the name 'GEMINI_API_KEY'.")
    print("3. Paste your API key into the 'Value' field.")
    print("-----------------------\n")


# --- Machine Learning Component 1: Optical Character Recognition (OCR) ---
# We use Tesseract, a powerful open-source OCR engine developed by Google.
# It employs pre-trained machine learning models (LSTMs) to recognize
# characters, words, and sentences in images.

def extract_text_from_image(image_path):
    """
    Extracts text from an image file using Tesseract OCR.
    Args:
        image_path (str): The file path to the image of handwritten notes.
    Returns:
        str: The extracted text from the image.
    """
    try:
        print(f"Opening image: {image_path}...")
        with Image.open(image_path) as img:
            print("Extracting text using Tesseract OCR...")
            extracted_text = pytesseract.image_to_string(img)
            print("Text extraction complete.")
            return extracted_text
    except FileNotFoundError:
        return "Error: Image file not found. Please check the file path."
    except Exception as e:
        return f"An error occurred during text extraction: {e}"


# --- NLP Component: Grammar and Spelling Correction ---
# We use 'language-tool-python', a library that acts as a wrapper for LanguageTool.
# LanguageTool is a rule-based system that finds and corrects grammar, style,
# and spelling errors. While not strictly ML, it's a core NLP task.

def correct_grammar_and_spelling(text):
    """
    Corrects grammatical and spelling mistakes in the given text.
    Args:
        text (str): The text to be corrected.
    Returns:
        str: The corrected text.
    """
    print("Initializing grammar correction tool (this may take a moment on first run)...")
    try:
        # Initialize the language tool. It will download necessary files on first use.
        tool = language_tool_python.LanguageTool('en-US')
        print("Applying grammar and spelling corrections...")
        corrected_text = tool.correct(text)
        print("Correction complete.")
        return corrected_text
    except Exception as e:
        print(f"Could not initialize or use the language tool. Error: {e}")
        return text # Return original text if correction fails


# --- Machine Learning Component 2: AI Content Enrichment ---
# This function uses Google's Gemini, a large language model (LLM).
# LLMs are advanced machine learning models trained on vast amounts of text data.
# We prompt the model to act as an expert and enrich the user's notes.

def enrich_content_with_ai(text):
    """
    Uses the Gemini API to enrich the corrected text with additional information.
    Args:
        text (str): The corrected notes to be enriched.
    Returns:
        str: A detailed, enriched version of the notes.
    """
    if not GEMINI_API_KEY:
        return "Error: Gemini API key is not configured. Cannot enrich content."

    print("Connecting to the Gemini API for content enrichment...")
    # Set up the generative model
    model = genai.GenerativeModel('gemini-pro')

    # The prompt is crucial. It tells the AI exactly what to do.
    prompt = f"""
    You are an expert educator and study assistant. Your task is to take the following student's notes, which have been transcribed from handwriting, and enrich them.

    Follow these steps:
    1.  First, present the student's original notes in a cleaned-up and corrected format.
    2.  Next, provide a "Key Concepts" section that summarizes the main points in a bulleted list.
    3.  Then, create an "In-Depth Explanation" section that elaborates on each key concept, providing clear definitions and context.
    4.  Finally, add a "Further Reading & Related Topics" section with suggestions for deeper learning, like related historical events, scientific principles, or key figures.

    Please format the entire output using Markdown for clarity.

    Here are the student's notes:
    ---
    {text}
    ---
    """

    try:
        response = model.generate_content(prompt)
        print("AI enrichment complete.")
        return response.text
    except Exception as e:
        return f"An error occurred with the Gemini API: {e}"


# --- Main Workflow Function ---
def process_handwritten_notes(image_path):
    """
    Orchestrates the entire process from image to enriched content.
    Args:
        image_path (str): The file path to the image of handwritten notes.
    """
    # Step 1: Extract text from the image
    raw_text = extract_text_from_image(image_path)
    if "Error:" in raw_text:
        print(raw_text)
        return

    print("\n--- Extracted Text ---\n")
    print(raw_text)

    # Step 2: Correct grammar and spelling
    corrected_text = correct_grammar_and_spelling(raw_text)
    print("\n--- Corrected Text ---\n")
    print(corrected_text)

    # Step 3: Enrich the content using AI
    enriched_notes = enrich_content_with_ai(corrected_text)
    print("\n--- AI Enriched Notes ---\n")
    print(enriched_notes)


# --- Example Usage ---
# To run this in Google Colab:
# 1.  Upload an image of your handwritten notes to your Colab session.
#     You can do this by clicking the "Files" icon on the left sidebar and then "Upload".
# 2.  Replace 'your_notes.jpg' with the actual filename of your uploaded image.
# 3.  Run the script.

if __name__ == '__main__':
    # Make sure to upload your image file to the Colab environment first!
    # For example, if you upload a file named 'history_notes.png'
    image_file = 'your_notes.jpg'  # <-- IMPORTANT: CHANGE THIS to your image file name

    if not os.path.exists(image_file):
        print(f"File '{image_file}' not found.")
        print("Please upload your notes image and update the 'image_file' variable.")
    else:
        process_handwritten_notes(image_file)

# Import necessary libraries
import os
from google.colab import files

def process_uploaded_file(file_path):
    """
    A placeholder function to demonstrate what happens after a file is uploaded.
    In the full script, this would trigger the OCR, correction, and enrichment.
    """
    print(f"\nSuccessfully received file: {file_path}")
    print("This file is now ready for processing.")
    # In a real application, you would call your main processing function here, e.g.:
    # process_handwritten_notes(file_path)

# --- Main Execution Block ---
# This code will only run when the script is executed directly.
if __name__ == '__main__':
    try:
        # 1. Prompt the user to upload a file.
        print("Please use the button below to upload an image of your notes.")

        # 2. Display the interactive upload widget in the Colab output.
        uploaded = files.upload()

        # 3. Check if any files were actually uploaded.
        if not uploaded:
            print("\nUpload cancelled or no file was selected.")
        else:
            # 4. Get the filename of the uploaded file.
            # 'next(iter(uploaded))' is a reliable way to get the first key (the filename)
            # from the 'uploaded' dictionary.
            image_file = next(iter(uploaded))

            # 5. Call the function to handle the uploaded file.
            process_uploaded_file(image_file)

    except Exception as e:
        print(f"An error occurred during the upload process: {e}")




# --- Add these functions to your script ---

def extract_text_from_image(image_path):
    """Extracts text from an image file using Tesseract OCR."""
    try:
        print(f"Opening image: {image_path}...")
        with Image.open(image_path) as img:
            print("Extracting text using Tesseract OCR...")
            return pytesseract.image_to_string(img)
    except Exception as e:
        return f"Error during text extraction: {e}"

def correct_grammar_and_spelling(text):
    """Corrects grammar and spelling mistakes."""
    print("Initializing grammar correction tool...")
    try:
        tool = language_tool_python.LanguageTool('en-US')
        print("Applying grammar and spelling corrections...")
        return tool.correct(text)
    except Exception as e:
        print(f"Could not use the language tool. Error: {e}", file=sys.stderr)
        return text # Return original text if correction fails

def enrich_content_with_ai(text):
    """Uses the Gemini API to enrich the corrected text."""
    # This function assumes you have already configured your GEMINI_API_KEY
    print("Connecting to the Gemini API for content enrichment...")
    model = genai.GenerativeModel('gemini-1.5-flash')
    prompt = f"""Please enrich the following notes by summarizing key concepts, providing in-depth explanations, and suggesting related topics for further reading. Format the output clearly using Markdown.

    Notes:
    ---
    {text}
    ---
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"An error occurred with the Gemini API. Please double-check your API key. Details: {e}"

def process_handwritten_notes(image_path):
    """Orchestrates the entire process from image to enriched content."""
    # Step 1: Extract text
    raw_text = extract_text_from_image(image_path)
    if not raw_text or raw_text.isspace():
        print("\n--- No Text Extracted ---")
        print("The OCR could not detect any text in the image. Please try a clearer image.")
        return

    print("\n--- 1. Extracted Text ---\n", raw_text)

    # Step 2: Correct grammar
    corrected_text = correct_grammar_and_spelling(raw_text)
    print("\n--- 2. Corrected Text ---\n", corrected_text)

    # Step 3: Enrich with AI
    enriched_notes = enrich_content_with_ai(corrected_text)
    print("\n--- 3. AI Enriched Notes ---\n", enriched_notes)


# --- Updated Main Execution Block ---
# Replace your script's file upload logic with this.

try:
    print("Please use the button below to upload an image of your notes.")
    uploaded = files.upload()

    if not uploaded:
        print("\nUpload cancelled.")
    else:
        # Get the filename of the uploaded file
        image_file = next(iter(uploaded))
        print(f"\nProcessing uploaded file: '{image_file}'...")

        # This now calls the full processing pipeline instead of the placeholder
        process_handwritten_notes(image_file)

except Exception as e:
    print(f"An unexpected error occurred: {e}", file=sys.stderr)

# Add these necessary imports at the top of your cell
import pytesseract
import language_tool_python
import google.generativeai as genai
from PIL import Image
import sys
from google.colab import files

# --- Core Processing Functions ---

def extract_text_from_image(image_path):
    """Extracts text from an image file using Tesseract OCR."""
    try:
        print(f"Opening image: {image_path}...")
        with Image.open(image_path) as img:
            print("Extracting text using Tesseract OCR...")
            return pytesseract.image_to_string(img)
    except Exception as e:
        return f"Error during text extraction: {e}"

def correct_grammar_and_spelling(text):
    """Corrects grammar and spelling mistakes."""
    print("Initializing grammar correction tool...")
    try:
        tool = language_tool_python.LanguageTool('en-US')
        print("Applying grammar and spelling corrections...")
        return tool.correct(text)
    except Exception as e:
        print(f"Could not use the language tool. Error: {e}", file=sys.stderr)
        return text # Return original text if correction fails

def enrich_content_with_ai(text):
    """Uses the Gemini API to enrich the corrected text."""
    # This function assumes you have already configured your GEMINI_API_KEY
    print("Connecting to the Gemini API for content enrichment...")
    model = genai.GenerativeModel('gemini-1.5-flash')
    prompt = f"""Please enrich the following notes by summarizing key concepts, providing in-depth explanations, and suggesting related topics for further reading. Format the output clearly using Markdown.

    Notes:
    ---
    {text}
    ---
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"An error occurred with the Gemini API. Please double-check your API key. Details: {e}"

def process_handwritten_notes(image_path):
    """Orchestrates the entire process from image to enriched content."""
    # Step 1: Extract text
    raw_text = extract_text_from_image(image_path)
    if not raw_text or raw_text.isspace():
        print("\n--- No Text Extracted ---")
        print("The OCR could not detect any text in the image. Please try a clearer image.")
        return

    print("\n--- 1. Extracted Text ---\n", raw_text)

    # Step 2: Correct grammar
    corrected_text = correct_grammar_and_spelling(raw_text)
    print("\n--- 2. Corrected Text ---\n", corrected_text)

    # Step 3: Enrich with AI
    enriched_notes = enrich_content_with_ai(corrected_text)
    print("\n--- 3. AI Enriched Notes ---\n", enriched_notes)


# --- Main Execution Block ---
# This single block handles the file upload and starts the processing.

try:
    print("Please use the button below to upload an image of your notes.")
    uploaded = files.upload()

    if not uploaded:
        print("\nUpload cancelled.")
    else:
        # Get the filename of the uploaded file
        image_file = next(iter(uploaded))
        print(f"\nProcessing uploaded file: '{image_file}'...")

        # This now calls the full processing pipeline
        process_handwritten_notes(image_file)

except Exception as e:
    print(f"An unexpected error occurred: {e}", file=sys.stderr)

from google.colab import userdata
userdata.get('DeepReadAI')

# Add these necessary imports at the top of your cell
# You may need to install opencv: !pip install opencv-python-headless
import pytesseract
import language_tool_python
import google.generativeai as genai
from PIL import Image
import sys
from google.colab import files
import cv2
import numpy as np
import re

# --- API Key Configuration ---
# This block securely fetches your API key from Colab's secrets manager.
try:
    # This import is only available in a Google Colab environment.
    from google.colab import userdata

    # Fetch the DeepReadAI API key.
    DEEPREADAI_API_KEY = userdata.get('DeepReadAI')
    if not DEEPREADAI_API_KEY:
        # This handles the case where the secret exists but is empty.
        print("Warning: Secret 'DeepReadAI' found but it is empty.")
    else:
        genai.configure(api_key=DEEPREADAI_API_KEY)

except ImportError:
    print("Warning: Not running in a Colab environment. API key needs to be set manually.")
except Exception as e:
    error_message = str(e)
    # Check for the specific "Secret does not exist" error from Colab.
    if "Secret" in error_message and "does not exist" in error_message:
        print("\n--- ACTION REQUIRED: API Key Secret Missing ---")
        print(f"The script failed because it could not find the secret named 'DeepReadAI'.")
        print("Please follow these steps to fix this:")
        print("1. In your Colab notebook, click the 'Key' icon (ðŸ”‘) on the left sidebar.")
        print("2. Click 'Add a new secret'.")
        print("3. In the 'Name' field, enter exactly: DeepReadAI")
        print("4. In the 'Value' field, paste your actual Google AI API key.")
        print("5. Make sure the 'Notebook access' toggle is ON.")
        print("6. Re-run this cell after creating the secret.")
        print("--------------------------------------------------\n")
    else:
        # For any other errors during setup.
        print(f"An unexpected error occurred during API key setup: {e}")


# --- Core Processing Functions ---

def extract_text_from_image(image_path):
    """
    Extracts text from an image using an updated pipeline that delegates orientation
    detection directly to the Tesseract engine for better accuracy.
    """
    try:
        print(f"Opening image with OpenCV: {image_path}...")
        img = cv2.imread(image_path)

        # 1. Convert to grayscale. This is a standard and effective pre-processing step.
        print("Pre-processing: Converting to grayscale...")
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # 2. Apply Otsu's thresholding to create a clean black-and-white image.
        # This is very effective at separating text from the background.
        print("Pre-processing: Applying Otsu's thresholding...")
        # We use THRESH_BINARY_INV to get black text on a white background, which Tesseract prefers.
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        # The image is inverted to ensure it's black text on white background
        thresh = cv2.bitwise_not(thresh)

        print("Extracting text using Tesseract OCR with automatic orientation detection...")
        # Custom Tesseract configuration.
        # PSM 1: Automatic page segmentation with OSD (Orientation and Script Detection).
        # This is the most robust setting for handling potentially rotated images automatically.
        custom_config = r'--oem 3 --psm 1'
        return pytesseract.image_to_string(thresh, config=custom_config)
    except Exception as e:
        return f"Error during text extraction: {e}"

def correct_grammar_and_spelling(text):
    """Corrects grammar and spelling mistakes."""
    print("Initializing grammar correction tool...")
    try:
        tool = language_tool_python.LanguageTool('en-US')
        print("Applying grammar and spelling corrections...")
        return tool.correct(text)
    except Exception as e:
        print(f"Could not use the language tool. Error: {e}", file=sys.stderr)
        return text # Return original text if correction fails

def enrich_content_with_ai(text):
    """Uses the Gemini API to enrich the corrected text after verifying the model."""
    if not text or text.isspace():
        return "Cannot enrich content because no text was extracted from the image."

    print("Connecting to the Gemini API for content enrichment...")

    try:
        # --- DIAGNOSTIC STEP: List available models ---
        print("--> Checking which AI models are available for your API key...")
        model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]

        if not model_list:
            return "Error: Your API key is valid, but no models are available. This might be a regional or permissions issue with your Google AI account."

        print(f"--> Available models: {model_list}")

        # --- MODEL SELECTION ---
        # Select a stable model that appears in your available list.
        model_name = 'gemini-pro-latest'
        if 'models/gemini-pro-latest' not in model_list:
            # Fallback to another common model if the preferred one isn't there
            if 'models/gemini-1.5-flash-latest' in model_list:
                 model_name = 'gemini-1.5-flash-latest'
            else:
                 model_name = model_list[0].replace('models/', '') # Fallback to the first available
            print(f"--> Preferred model not found. Using fallback: {model_name}")

        model = genai.GenerativeModel(model_name)

        prompt = f"""Please enrich the following notes by summarizing key concepts, providing in-depth explanations, and suggesting related topics for further reading. Format the output clearly using Markdown.

        Notes:
        ---
        {text}
        ---
        """

        response = model.generate_content(prompt)
        return response.text

    except Exception as e:
        error_message = str(e)
        if "429" in error_message and "Quota exceeded" in error_message:
            # This is the specific error the user is getting. Provide a clear explanation.
            quota_error_explanation = """
    --- API Quota Error ---
    A '429 Quota Exceeded' error occurred. This is not a code error.
    It means you have used all the free requests available for your Gemini API key.

    To fix this, you must:
    1. Go to your Google Cloud Console.
    2. Find the project linked to your API key.
    3. Ensure that **billing is enabled** for that project. The Gemini API requires billing to be set up to use it beyond the initial free tier.

    This script cannot fix this for you. You must configure your Google Cloud account settings.
            """
            return quota_error_explanation
        else:
            return f"An error occurred with the Gemini API. Please double-check your API key and ensure it is enabled. Details: {e}"

def process_handwritten_notes(image_path):
    """Orchestrates the entire process from image to enriched content."""
    # Step 1: Extract text
    raw_text = extract_text_from_image(image_path)
    if "Error" in raw_text:
        print(raw_text)
        return

    print("\n--- 1. Extracted Text ---\n", raw_text)

    # Step 2: Correct grammar
    corrected_text = correct_grammar_and_spelling(raw_text)
    print("\n--- 2. Corrected Text ---\n", corrected_text)

    # Step 3: Enrich with AI
    enriched_notes = enrich_content_with_ai(corrected_text)
    print("\n--- 3. AI Enriched Notes ---\n", enriched_notes)


# --- Main Execution Block ---
# This single block handles the file upload and starts the processing.

try:
    print("Please use the button below to upload an image of your notes.")
    uploaded = files.upload()

    if not uploaded:
        print("\nUpload cancelled.")
    else:
        # Get the filename of the uploaded file
        image_file = next(iter(uploaded))
        print(f"\nProcessing uploaded file: '{image_file}'...")

        # This now calls the full processing pipeline
        process_handwritten_notes(image_file)

except Exception as e:
    print(f"An unexpected error occurred: {e}", file=sys.stderr)

# Add these necessary imports at the top of your cell
# NOTE: opencv, pytesseract, and language-tool-python are no longer needed.
import google.generativeai as genai
from PIL import Image
import sys
from google.colab import files
import re

# --- API Key Configuration ---
# This block securely fetches your API key from Colab's secrets manager.
try:
    # This import is only available in a Google Colab environment.
    from google.colab import userdata

    # Fetch the DeepReadAI API key.
    DEEPREADAI_API_KEY = userdata.get('DeepReadAI')
    if not DEEPREADAI_API_KEY:
        # This handles the case where the secret exists but is empty.
        print("Warning: Secret 'DeepReadAI' found but it is empty.")
    else:
        genai.configure(api_key=DEEPREADAI_API_KEY)

except ImportError:
    print("Warning: Not running in a Colab environment. API key needs to be set manually.")
except Exception as e:
    error_message = str(e)
    # Check for the specific "Secret does not exist" error from Colab.
    if "Secret" in error_message and "does not exist" in error_message:
        print("\n--- ACTION REQUIRED: API Key Secret Missing ---")
        print(f"The script failed because it could not find the secret named 'DeepReadAI'.")
        print("Please follow these steps to fix this:")
        print("1. In your Colab notebook, click the 'Key' icon (ðŸ”‘) on the left sidebar.")
        print("2. Click 'Add a new secret'.")
        print("3. In the 'Name' field, enter exactly: DeepReadAI")
        print("4. In the 'Value' field, paste your actual Google AI API key.")
        print("5. Make sure the 'Notebook access' toggle is ON.")
        print("6. Re-run this cell after creating the secret.")
        print("--------------------------------------------------\n")
    else:
        # For any other errors during setup.
        print(f"An unexpected error occurred during API key setup: {e}")


# --- ALTERNATIVE: Multimodal AI Processing ---
# This single function replaces the entire old pipeline (extract, correct, enrich).
# It uses a multimodal model that can directly understand images.

def generate_enriched_notes_from_image(image_path):
    """
    Directly processes an image of handwritten notes using a multimodal AI,
    combining text extraction, correction, and enrichment into a single step.
    """
    try:
        print(f"Opening image: {image_path}...")
        img = Image.open(image_path)

        # --- DYNAMIC MODEL SELECTION TO PREVENT 404 ERRORS ---
        print("--> Checking available AI models for your API key...")
        model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]

        # Define a list of preferred vision models in order of preference.
        preferred_models = [
            'models/gemini-1.5-pro-latest',
            'models/gemini-1.5-flash-latest',
            'models/gemini-pro-vision' # A stable fallback
        ]

        model_name = None
        for m in preferred_models:
            if m in model_list:
                model_name = m
                break # Stop when the first preferred model is found

        if not model_name:
            # If no preferred models are found, find the first available model that can handle images.
            # This makes the script more resilient to future model name changes.
            vision_fallbacks = [m for m in model_list if 'vision' in m or 'flash' in m]
            if vision_fallbacks:
                model_name = vision_fallbacks[0]
            else:
                 return "Error: Could not find a suitable vision-capable AI model for your API key."

        print(f"--> Using model: {model_name.replace('models/', '')}")
        model = genai.GenerativeModel(model_name)


        # This new prompt asks the AI to perform all steps at once.
        prompt = """
        You are an expert educator and study assistant. Your task is to analyze the provided image of handwritten notes and generate enriched content from it.

        Follow these steps precisely:
        1.  **Transcribe the Text:** Carefully read all the handwritten text in the image and transcribe it accurately.
        2.  **Correct and Clean:** Correct any spelling or grammar mistakes in the transcribed text.
        3.  **Enrich the Content:** Based on the corrected text, generate a detailed study guide. This guide should include:
            * A "Key Concepts" section summarizing the main points.
            * An "In-Depth Explanation" section elaborating on each concept.
            * A "Further Reading & Related Topics" section with suggestions for deeper learning.

        Please format the final output using clear Markdown. Start with the enriched content directly.
        """

        print("Sending image to the multimodal AI for processing...")
        # The model is given both the detailed prompt and the image itself.
        response = model.generate_content([prompt, img])

        print("AI processing complete.")
        return response.text

    except Exception as e:
        error_message = str(e)
        if "429" in error_message and "Quota exceeded" in error_message:
            quota_error_explanation = """
    --- API Quota Error ---
    A '429 Quota Exceeded' error occurred. This is not a code error. It means you have used all the free requests available for your Gemini API key.
    To fix this, you must enable billing on the Google Cloud project linked to your API key.
            """
            return quota_error_explanation
        else:
            return f"An error occurred with the Gemini API. Details: {e}"


# --- Main Execution Block ---
# This block handles the file upload and starts the new, simplified processing.

try:
    print("Please use the button below to upload an image of your notes.")
    uploaded = files.upload()

    if not uploaded:
        print("\nUpload cancelled.")
    else:
        # Get the filename of the uploaded file
        image_file = next(iter(uploaded))
        print(f"\nProcessing uploaded file: '{image_file}'...")

        # This now calls the single, powerful multimodal function.
        enriched_notes = generate_enriched_notes_from_image(image_file)

        print("\n--- AI Generated & Enriched Notes ---\n")
        print(enriched_notes)

except Exception as e:
    print(f"An unexpected error occurred: {e}", file=sys.stderr)

# Add these necessary imports at the top of your cell
# NOTE: opencv, pytesseract, and language-tool-python are no longer needed.
import google.generativeai as genai
from PIL import Image
import sys
from google.colab import files
import re

# --- API Key Configuration ---
# This block securely fetches your API key from Colab's secrets manager.
try:
    # This import is only available in a Google Colab environment.
    from google.colab import userdata

    # Fetch the DeepReadAI API key.
    DEEPREADAI_API_KEY = userdata.get('DeepReadAI')
    if not DEEPREADAI_API_KEY:
        # This handles the case where the secret exists but is empty.
        print("Warning: Secret 'DeepReadAI' found but it is empty.")
    else:
        genai.configure(api_key=DEEPREADAI_API_KEY)

except ImportError:
    print("Warning: Not running in a Colab environment. API key needs to be set manually.")
except Exception as e:
    error_message = str(e)
    # Check for the specific "Secret does not exist" error from Colab.
    if "Secret" in error_message and "does not exist" in error_message:
        print("\n--- ACTION REQUIRED: API Key Secret Missing ---")
        print(f"The script failed because it could not find the secret named 'DeepReadAI'.")
        print("Please follow these steps to fix this:")
        print("1. In your Colab notebook, click the 'Key' icon (ðŸ”‘) on the left sidebar.")
        print("2. Click 'Add a new secret'.")
        print("3. In the 'Name' field, enter exactly: DeepReadAI")
        print("4. In the 'Value' field, paste your actual Google AI API key.")
        print("5. Make sure the 'Notebook access' toggle is ON.")
        print("6. Re-run this cell after creating the secret.")
        print("--------------------------------------------------\n")
    else:
        # For any other errors during setup.
        print(f"An unexpected error occurred during API key setup: {e}")


# --- ALTERNATIVE: Multimodal AI Processing ---
# This single function replaces the entire old pipeline (extract, correct, enrich).
# It uses a multimodal model that can directly understand images.

def generate_enriched_notes_from_image(image_path):
    """
    Directly processes an image of handwritten notes using a multimodal AI,
    combining text extraction, correction, and enrichment into a single step.
    """
    try:
        print(f"Opening image: {image_path}...")
        img = Image.open(image_path)

        # --- DYNAMIC MODEL SELECTION TO PREVENT 404 ERRORS ---
        print("--> Checking available AI models for your API key...")
        model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]

        # Define a list of preferred vision models in order of preference.
        preferred_models = [
            'models/gemini-1.5-pro-latest',
            'models/gemini-1.5-flash-latest',
            'models/gemini-pro-vision' # A stable fallback
        ]

        model_name = None
        for m in preferred_models:
            if m in model_list:
                model_name = m
                break # Stop when the first preferred model is found

        if not model_name:
            # If no preferred models are found, find the first available model that can handle images.
            # This makes the script more resilient to future model name changes.
            vision_fallbacks = [m for m in model_list if 'vision' in m or 'flash' in m]
            if vision_fallbacks:
                model_name = vision_fallbacks[0]
            else:
                 return "Error: Could not find a suitable vision-capable AI model for your API key."

        print(f"--> Using model: {model_name.replace('models/', '')}")
        model = genai.GenerativeModel(model_name)


        # This new prompt asks the AI to perform all steps at once.
        prompt = """
        You are an expert educator and study assistant. Your task is to analyze the provided image of handwritten notes and generate enriched content from it.

        Follow these steps precisely:
        1.  **Transcribe the Text:** Carefully read all the handwritten text in the image and transcribe it accurately.
        2.  **Correct and Clean:** Correct any spelling or grammar mistakes in the transcribed text.
        3.  **Enrich the Content:** Based on the corrected text, generate a detailed study guide. This guide should include:
            * A "Key Concepts" section summarizing the main points.
            * An "In-Depth Explanation" section elaborating on each concept.
            * A "Further Reading & Related Topics" section with suggestions for deeper learning.

        Please format the final output using clear Markdown. Start with the enriched content directly.
        """

        print("Sending image to the multimodal AI for processing...")
        # The model is given both the detailed prompt and the image itself.
        response = model.generate_content([prompt, img])

        print("AI processing complete.")
        return response.text

    except Exception as e:
        error_message = str(e)
        if "429" in error_message and "Quota exceeded" in error_message:
            quota_error_explanation = """
    --- API Quota Error ---
    A '429 Quota Exceeded' error occurred. This is not a code error. It means you have used all the free requests available for your Gemini API key.
    To fix this, you must enable billing on the Google Cloud project linked to your API key.
            """
            return quota_error_explanation
        else:
            return f"An error occurred with the Gemini API. Details: {e}"


# --- Main Execution Block ---
# This block handles the file upload and starts the new, simplified processing.

try:
    print("Please use the button below to upload an image of your notes.")
    uploaded = files.upload()

    if not uploaded:
        print("\nUpload cancelled.")
    else:
        # Get the filename of the uploaded file
        image_file = next(iter(uploaded))
        print(f"\nProcessing uploaded file: '{image_file}'...")

        # This now calls the single, powerful multimodal function.
        enriched_notes = generate_enriched_notes_from_image(image_file)

        print("\n--- AI Generated & Enriched Notes ---\n")
        print(enriched_notes)

except Exception as e:
    print(f"An unexpected error occurred: {e}", file=sys.stderr)

python app.py

!python app.py

# Add these necessary imports at the top of your cell
# NOTE: opencv, pytesseract, and language-tool-python are no longer needed.
import google.generativeai as genai
from PIL import Image
import sys
from google.colab import files
import re

# --- API Key Configuration ---
# This block securely fetches your API key from Colab's secrets manager.
try:
    # This import is only available in a Google Colab environment.
    from google.colab import userdata

    # Fetch the DeepReadAI API key.
    DEEPREADAI_API_KEY = userdata.get('DeepReadAI')
    if not DEEPREADAI_API_KEY:
        # This handles the case where the secret exists but is empty.
        print("Warning: Secret 'DeepReadAI' found but it is empty.")
    else:
        genai.configure(api_key=DEEPREADAI_API_KEY)

except ImportError:
    print("Warning: Not running in a Colab environment. API key needs to be set manually.")
except Exception as e:
    error_message = str(e)
    # Check for the specific "Secret does not exist" error from Colab.
    if "Secret" in error_message and "does not exist" in error_message:
        print("\n--- ACTION REQUIRED: API Key Secret Missing ---")
        print(f"The script failed because it could not find the secret named 'DeepReadAI'.")
        print("Please follow these steps to fix this:")
        print("1. In your Colab notebook, click the 'Key' icon (ðŸ”‘) on the left sidebar.")
        print("2. Click 'Add a new secret'.")
        print("3. In the 'Name' field, enter exactly: DeepReadAI")
        print("4. In the 'Value' field, paste your actual Google AI API key.")
        print("5. Make sure the 'Notebook access' toggle is ON.")
        print("6. Re-run this cell after creating the secret.")
        print("--------------------------------------------------\n")
    else:
        # For any other errors during setup.
        print(f"An unexpected error occurred during API key setup: {e}")


# --- ALTERNATIVE: Multimodal AI Processing ---
# This single function replaces the entire old pipeline (extract, correct, enrich).
# It uses a multimodal model that can directly understand images.

def generate_enriched_notes_from_image(image_path):
    """
    Directly processes an image of handwritten notes using a multimodal AI,
    combining text extraction, correction, and enrichment into a single step.
    """
    try:
        print(f"Opening image: {image_path}...")
        img = Image.open(image_path)

        # --- DYNAMIC MODEL SELECTION TO PREVENT 404 ERRORS ---
        print("--> Checking available AI models for your API key...")
        model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]

        # Define a list of preferred vision models in order of preference.
        preferred_models = [
            'models/gemini-1.5-pro-latest',
            'models/gemini-1.5-flash-latest',
            'models/gemini-pro-vision' # A stable fallback
        ]

        model_name = None
        for m in preferred_models:
            if m in model_list:
                model_name = m
                break # Stop when the first preferred model is found

        if not model_name:
            # If no preferred models are found, find the first available model that can handle images.
            # This makes the script more resilient to future model name changes.
            vision_fallbacks = [m for m in model_list if 'vision' in m or 'flash' in m]
            if vision_fallbacks:
                model_name = vision_fallbacks[0]
            else:
                 return "Error: Could not find a suitable vision-capable AI model for your API key."

        print(f"--> Using model: {model_name.replace('models/', '')}")
        model = genai.GenerativeModel(model_name)


        # This new prompt asks the AI to perform all steps at once.
        prompt = """
        You are an expert educator and study assistant. Your task is to analyze the provided image of handwritten notes and generate enriched content from it.

        Follow these steps precisely:
        1.  **Transcribe the Text:** Carefully read all the handwritten text in the image and transcribe it accurately.
        2.  **Correct and Clean:** Correct any spelling or grammar mistakes in the transcribed text.
        3.  **Enrich the Content:** Based on the corrected text, generate a detailed study guide. This guide should include:
            * A "Key Concepts" section summarizing the main points.
            * An "In-Depth Explanation" section elaborating on each concept.
            * A "Further Reading & Related Topics" section with suggestions for deeper learning.

        Please format the final output using clear Markdown. Start with the enriched content directly.
        """

        print("Sending image to the multimodal AI for processing...")
        # The model is given both the detailed prompt and the image itself.
        response = model.generate_content([prompt, img])

        print("AI processing complete.")
        return response.text

    except Exception as e:
        error_message = str(e)
        if "429" in error_message and "Quota exceeded" in error_message:
            quota_error_explanation = """
    --- API Quota Error ---
    A '429 Quota Exceeded' error occurred. This is not a code error. It means you have used all the free requests available for your Gemini API key.
    To fix this, you must enable billing on the Google Cloud project linked to your API key.
            """
            return quota_error_explanation
        else:
            return f"An error occurred with the Gemini API. Details: {e}"


# --- Main Execution Block ---
# This block handles the file upload and starts the new, simplified processing.

try:
    print("Please use the button below to upload an image of your notes.")
    uploaded = files.upload()

    if not uploaded:
        print("\nUpload cancelled.")
    else:
        # Get the filename of the uploaded file
        image_file = next(iter(uploaded))
        print(f"\nProcessing uploaded file: '{image_file}'...")

        # This now calls the single, powerful multimodal function.
        enriched_notes = generate_enriched_notes_from_image(image_file)

        print("\n--- AI Generated & Enriched Notes ---\n")
        print(enriched_notes)

except Exception as e:
    print(f"An unexpected error occurred: {e}", file=sys.stderr)

!git push

# Configure your git identity (replace with your email and name)
!git config --global user.email "rithishree666@gmail.com"
!git config --global user.name "rithishree"

!git init -b main

!git add .

!git commit -m "Initial commit of DeepRead AI website"

!git remote remove origin

!git remote add origin https://github.com/rithishree/deepread-ai-website.git

!git push -u origin main

